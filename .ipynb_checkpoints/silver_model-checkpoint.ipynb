{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GitHub link for the talk. You can clone the data and play with it yourself. Please submit any improvements as pull requests\n",
    "\n",
    "[https://github.com/jseabold/538model](https://github.com/jseabold/538model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'pandas' has no attribute 'set_printoptions'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-bb9a377c6983>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_printoptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprecision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuppress\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m pandas.set_printoptions(notebook_repr_html=False,\n\u001b[0m\u001b[1;32m     10\u001b[0m                         \u001b[0mprecision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                         \u001b[0mmax_columns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn_space\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'pandas' has no attribute 'set_printoptions'"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "from scipy import stats\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "pandas.set_printoptions(notebook_repr_html=False,\n",
    "                        precision=4,\n",
    "                        max_columns=12, column_space=10,\n",
    "                        max_colwidth=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = datetime.datetime(2012, 10, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Methodology was obtained from the old [538 Blog](http://www.fivethirtyeight.com/2008/03/frequently-asked-questions-last-revised.html) with updates at the [new site hosted by the New York Times](http://fivethirtyeight.blogs.nytimes.com/methodology/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Polling Average: Aggregate polling data, and weight it according to our reliability scores.\n",
    "\n",
    "2. Trend Adjustment: Adjust the polling data for current trends.\n",
    "\n",
    "3. Regression: Analyze demographic data in each state by means of regression analysis.\n",
    "\n",
    "4. Snapshot: Combine the polling data with the regression analysis to produce an electoral snapshot. This is our estimate of what would happen if the election were held today.\n",
    "\n",
    "5. Projection: Translate the snapshot into a projection of what will happen in November, by allocating out undecided voters and applying a discount to current polling leads based on historical trends.\n",
    "\n",
    "6. Simulation: Simulate our results 10,000 times based on the results of the projection to account for the uncertainty in our estimates. The end result is a robust probabilistic assessment of what will happen in each state as well as in the nation as a whole. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consensus forecast of GDP growth over the next two economic quarters <br />(Median of WSJ's monthly forecasting panel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The process for creating an economic index for the 538 model is described [here](http://fivethirtyeight.blogs.nytimes.com/2012/07/05/measuring-the-effect-of-the-economy-on-elections/#more-31732)."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Obtained from WSJ.com on 10/2/12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecasts = pandas.read_table(\"/home/skipper/school/seaboldgit/\"\n",
    "                              \"talks/pydata/data/wsj_forecast.csv\", skiprows=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecasts.rename(columns={\"Q3 2012\" : \"gdp_q3_2012\", \n",
    "                          \"Q4 2012\" : \"gdp_q4_2012\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecasts"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Pandas methods are NaN aware, so we can just get the median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_forecast = forecasts[['gdp_q3_2012', 'gdp_q4_2012']].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Economics State Variables from FRED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Job Growth (Nonfarm-payrolls) **PAYEMS** <br />\n",
    "Personal Income **PI** <br />\n",
    "Industrial production **INDPRO** <br />\n",
    "Consumption **PCEC96** <br />\n",
    "Inflation **CPIAUCSL** <br />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.io.data import DataReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = dict(jobs = \"PAYEMS\",\n",
    "              income = \"PI\",\n",
    "              prod = \"INDPRO\",\n",
    "              cons = \"PCEC96\",\n",
    "              prices = \"CPIAUCSL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#indicators = []\n",
    "#for variable in series:\n",
    "#    data = DataReader(series[variable], \"fred\", start=\"2010-1-1\")\n",
    "#    # renaming not necessary in master\n",
    "#    data.rename(columns={\"VALUE\" : variable}, inplace=True)\n",
    "#    indicators.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#indicators = pandas.concat(indicators, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#indicators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polling Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used Python to scrape the [Real Clear Politics](realclearpolitics.com) website and download data for the 2004 and 2008 elections. The scraping scripts are available in the github repository for this talk. State by state historical data for the 2004 and 2008 Presidential elections was obtained from [electoral-vote.com](www.electorical-vote.com)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polling Average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Details can be found at the 538 blog [here](http://www.fivethirtyeight.com/2008/03/pollster-ratings-updated.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tossup = [\"Colorado\", \"Florida\", \"Iowa\", \"New Hampshire\", \"Nevada\", \n",
    "          \"Ohio\", \"Virginia\", \"Wisconsin\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "national_data2012 = pandas.read_table(\"/home/skipper/school/seaboldgit/talks/pydata/\"\n",
    "                                      \"data/2012_poll_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "national_data2012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "national_data2012.rename(columns={\"Poll\" : \"Pollster\"}, inplace=True)\n",
    "national_data2012[\"obama_spread\"] = national_data2012[\"Obama (D)\"] - national_data2012[\"Romney (R)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "national_data2012[\"State\"] = \"USA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_data2012 = pandas.read_table(\"/home/skipper/school/seaboldgit/talks/pydata/data/2012_poll_data_states.csv\")\n",
    "state_data2012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_data2012[\"obama_spread\"] = state_data2012[\"Obama (D)\"] - state_data2012[\"Romney (R)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_data2012.rename(columns=dict(Poll=\"Pollster\"), inplace=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_data2012.MoE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_data2012.MoE = state_data2012.MoE.replace(\"--\", \"nan\").astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_data2012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_data2012 = state_data2012.set_index([\"Pollster\", \"State\", \"Date\"]).drop(\"RCP Average\", level=0).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_data2012.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean up the sample numbers to make it a number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_data2012.Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_data2012.Sample = state_data2012.Sample.str.replace(\"\\s*([L|R]V)|A\", \"\") # 20 RV\n",
    "state_data2012.Sample = state_data2012.Sample.str.replace(\"\\s*--\", \"nan\") # --\n",
    "state_data2012.Sample = state_data2012.Sample.str.replace(\"^$\", \"nan\")\n",
    "\n",
    "national_data2012.Sample = national_data2012.Sample.str.replace(\"\\s*([L|R]V)|A\", \"\") # 20 RV\n",
    "national_data2012.Sample = national_data2012.Sample.str.replace(\"\\s*--\", \"nan\") # --\n",
    "national_data2012.Sample = national_data2012.Sample.str.replace(\"^$\", \"nan\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_data2012.Sample.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_data2012.Sample = state_data2012.Sample.astype(float)\n",
    "national_data2012.Sample = national_data2012.Sample.astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 2012 data is currently in order of time by state but doesn't have any years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dates2012.get_group((\"OH\", \"NBC News/Marist\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_data2012[\"start_date\"] = \"\"\n",
    "state_data2012[\"end_date\"] = \"\"\n",
    "dates2012 = state_data2012.groupby([\"State\", \"Pollster\"])[\"Date\"]\n",
    "for _, date in dates2012:\n",
    "    year = 2012\n",
    "    # checked by hand, none straddle years\n",
    "    changes = np.r_[False, np.diff(map(int, [i[0].split('/')[0] for \n",
    "                    i in date.str.split(' - ')])) > 0]\n",
    "    for j, (idx, dt) in enumerate(date.iteritems()):\n",
    "        dt1, dt2 = dt.split(\" - \")\n",
    "        year -= changes[j]\n",
    "        # check for ones that haven't polled in a year - soft check\n",
    "        # could be wrong for some...\n",
    "        if year == 2012 and (int(dt1.split(\"/\")[0]) > today.month and \n",
    "                             int(dt1.split(\"/\")[1]) > today.day):\n",
    "            year -= 1\n",
    "        dt1 += \"/\" + str(year)\n",
    "        dt2 += \"/\" + str(year)\n",
    "        state_data2012.set_value(idx, \"start_date\", dt1)\n",
    "        state_data2012.set_value(idx, \"end_date\", dt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "national_data2012[\"start_date\"] = \"\"\n",
    "national_data2012[\"end_date\"] = \"\"\n",
    "dates2012 = national_data2012.groupby([\"Pollster\"])[\"Date\"]\n",
    "for _, date in dates2012:\n",
    "    year = 2012\n",
    "    # checked by hand, none straddle years\n",
    "    changes = np.r_[False, np.diff(map(int, [i[0].split('/')[0] for \n",
    "                    i in date.str.split(' - ')])) > 0]\n",
    "    for j, (idx, dt) in enumerate(date.iteritems()):\n",
    "        dt1, dt2 = dt.split(\" - \")\n",
    "        year -= changes[j]\n",
    "        dt1 += \"/\" + str(year)\n",
    "        dt2 += \"/\" + str(year)\n",
    "        national_data2012.set_value(idx, \"start_date\", dt1)\n",
    "        national_data2012.set_value(idx, \"end_date\", dt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_data2012.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_data2012.start_date = state_data2012.start_date.apply(pandas.datetools.parse)\n",
    "state_data2012.end_date = state_data2012.end_date.apply(pandas.datetools.parse)\n",
    "\n",
    "national_data2012.start_date = national_data2012.start_date.apply(pandas.datetools.parse)\n",
    "national_data2012.end_date = national_data2012.end_date.apply(pandas.datetools.parse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def median_date(row):\n",
    "    dates = pandas.date_range(row[\"start_date\"], row[\"end_date\"])\n",
    "    median_idx = int(np.median(range(len(dates)))+.5)\n",
    "    return dates[median_idx]\n",
    "    \n",
    "state_data2012[\"poll_date\"] = [median_date(row) for i, row in state_data2012.iterrows()]\n",
    "del state_data2012[\"Date\"]\n",
    "del state_data2012[\"start_date\"]\n",
    "del state_data2012[\"end_date\"]\n",
    "\n",
    "national_data2012[\"poll_date\"] = [median_date(row) for i, row in national_data2012.iterrows()]\n",
    "del national_data2012[\"Date\"]\n",
    "del national_data2012[\"start_date\"]\n",
    "del national_data2012[\"end_date\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_data2012.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pollsters = state_data2012.Pollster.unique()\n",
    "pollsters.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pollsters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print pandas.Series(pollsters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 538 Pollster Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = pandas.read_table(\"/home/skipper/school/seaboldgit/talks/pydata/data/pollster_weights.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean up the pollster names a bit so we can merge with the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pollster_map = pickle.load(open(\"/home/skipper/school/seaboldgit/talks/pydata/data/pollster_map.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_data2012.Pollster.replace(pollster_map, inplace=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "national_data2012.Pollster.replace(pollster_map, inplace=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inner merge the data with the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_data2012 = state_data2012.merge(weights, how=\"inner\", on=\"Pollster\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_data2012.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First, we average each pollster for each state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first adjustment is an exponential decay for recency of the poll. Based on research in prior elections, a weight with a half-life of 30 days since the median date the poll has been in the field is assigned to each poll."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp_decay(days):\n",
    "    # defensive coding, accepts timedeltas\n",
    "    days = getattr(days, \"days\", days)\n",
    "    return .5 ** (days/30.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,8), subplot_kw={\"xlabel\" : \"Days\",\n",
    "                                                   \"ylabel\" : \"Weight\"})\n",
    "days = np.arange(0, 45)\n",
    "ax.plot(days, exp_decay(days));\n",
    "ax.vlines(30, 0, .99, color='r', linewidth=4)\n",
    "ax.set_ylim(0,1)\n",
    "ax.set_xlim(0, 45);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second adjustment is for the sample size of the poll. Polls with a higher sample size receive a higher weight."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binomial sampling error = +/- $50 * \\frac{1}{\\sqrt{nobs}}$ where the 50 depends on the underlying probability or population preferences, in this case assumed to be 50:50 (another way of calculating Margin of Error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_error(nobs, p=50.):\n",
    "    return p*nobs**-.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The thinking here is that having 5 polls of 1200 is a lot like having one poll of 6000. However, we downweight older polls by only including the marginal effective sample size. Where the effective sample size is the size of the methodologically perfect poll for which we would be indifferent between it and the one we have with our current total error. Total error is determined as $TE = \\text{Average Error} + \\text{Long Run Pollster Induced Error}$. See [here](http://www.fivethirtyeight.com/2008/04/pollster-ratings-v30.html) for the detailed calculations of Pollster Induced Error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def effective_sample(total_error, p=50.):\n",
    "    return p**2 * (total_error**-2.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_pollsters = state_data2012.groupby([\"State\", \"Pollster\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppp_az = state_pollsters.get_group((\"AZ\", \"Public Policy Polling (PPP)\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_idx = [\"Pollster\", \"State\", \"Obama (D)\", \"Romney (R)\", \"Sample\", \"poll_date\"]\n",
    "ppp_az[var_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppp_az.sort(\"poll_date\", ascending=False, inplace=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppp_az[\"cumulative\"] = ppp_az[\"Sample\"].cumsum()\n",
    "ppp_az[\"average_error\"] = average_error(ppp_az[\"cumulative\"])\n",
    "ppp_az[\"total_error\"] = ppp_az[\"PIE\"] + ppp_az[\"average_error\"]\n",
    "ppp_az[var_idx + [\"cumulative\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppp_az[\"ESS\"] = effective_sample(ppp_az[\"total_error\"])\n",
    "ppp_az[\"MESS\"] = ppp_az[\"ESS\"].diff()\n",
    "# fill in first one\n",
    "ppp_az[\"MESS\"].fillna(ppp_az[\"ESS\"].head(1).item(), inplace=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppp_az[[\"poll_date\", \"Sample\", \"cumulative\", \"ESS\", \"MESS\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's do it for every polling firm in every state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mess(group):\n",
    "    cumulative = group[\"Sample\"].cumsum()\n",
    "    ae = average_error(cumulative)\n",
    "    total_error = ae + group[\"PIE\"]\n",
    "    ess = effective_sample(total_error)\n",
    "    mess = ess.diff()\n",
    "    mess.fillna(ess.head(1).item(), inplace=True)\n",
    "    #from IPython.core.debugger import Pdb; Pdb().set_trace()\n",
    "    return pandas.concat((ess, mess), axis=1)\n",
    "\n",
    "#state_data2012[\"ESS\", \"MESS\"] \n",
    "df = state_pollsters.apply(calculate_mess)\n",
    "df.rename(columns={0 : \"ESS\", 1 : \"MESS\"}, inplace=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_data2012 = state_data2012.join(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Give them the time weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "td = today - state_data2012[\"poll_date\"].head(1).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_data2012[\"poll_date\"].head(1).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "td"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_data2012[\"time_weight\"] = (today - state_data2012[\"poll_date\"]).apply(exp_decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now aggregate all of these. Weight them based on the sample size but also based on the time_weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_mean(group):\n",
    "    weights1 = group[\"time_weight\"]\n",
    "    weights2 = group[\"MESS\"]\n",
    "    return np.sum(weights1*weights2*group[\"obama_spread\"]/(weights1*weights2).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_pollsters = state_data2012.groupby([\"State\", \"Pollster\"])\n",
    "state_polls = state_pollsters.apply(weighted_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_polls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2004 and 2008 Polls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_data2004 = pandas.read_csv(\"/home/skipper/school/seaboldgit/talks/pydata/data/2004-pres-polls.csv\")\n",
    "state_data2004"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_data2004.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_data2008 = pandas.read_csv(\"/home/skipper/school/seaboldgit/talks/pydata/data/2008-pres-polls.csv\")\n",
    "state_data2008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_data2008.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_data2008.End + \" 2008\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(state_data2008.End + \" 2008\").apply(pandas.datetools.parse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to clean some of the dates in this data. Luckily, pandas makes this easy to do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_data2004.Date = state_data2004.Date.str.replace(\"Nov 00\", \"Nov 01\")\n",
    "state_data2004.Date = state_data2004.Date.str.replace(\"Oct 00\", \"Oct 01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_data2008[\"poll_date\"] = (state_data2008.End + \" 2008\").apply(pandas.datetools.parse)\n",
    "state_data2004[\"poll_date\"] = (state_data2004.Date + \" 2004\").apply(pandas.datetools.parse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del state_data2008[\"End\"]\n",
    "del state_data2008[\"Start\"]\n",
    "del state_data2004[\"Date\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_data2008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_data2004"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_groups = state_data2008.groupby(\"State\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_groups.aggregate(dict(Obama=np.mean, McCain=np.mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Means for the entire country (without weighting by population)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_groups.aggregate(dict(Obama=np.mean, McCain=np.mean)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_data2004.Pollster.replace(pollster_map, inplace=True)\n",
    "state_data2008.Pollster.replace(pollster_map, inplace=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_data2004 = state_data2004.merge(weights, how=\"inner\", on=\"Pollster\")\n",
    "state_data2008 = state_data2008.merge(weights, how=\"inner\", on=\"Pollster\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(state_data2004.Pollster.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(state_data2008.Pollster.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date2004 = datetime.datetime(2004, 11, 2)\n",
    "date2004"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(date2004 - state_data2004.poll_date) < datetime.timedelta(21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restrict the samples to the 3 weeks leading up to the election"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_data2004 = state_data2004.ix[(date2004 - state_data2004.poll_date) <= datetime.timedelta(21)]\n",
    "state_data2004.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date2008 = datetime.datetime(2008, 11, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_data2008 = state_data2008.ix[(date2008 - state_data2008.poll_date) <= datetime.timedelta(21)]\n",
    "state_data2008.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_data2008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_data2004[\"time_weight\"] =(date2004 - state_data2004.poll_date).apply(exp_decay)\n",
    "state_data2008[\"time_weight\"] =(date2008 - state_data2008.poll_date).apply(exp_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_data2004[[\"time_weight\", \"poll_date\"]].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_date(x):\n",
    "    return x == x.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_data2004[\"newest_poll\"] = state_data2004.groupby((\"State\", \"Pollster\")).poll_date.transform(max_date)\n",
    "state_data2008[\"newest_poll\"] = state_data2008.groupby((\"State\", \"Pollster\")).poll_date.transform(max_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering States by Demographics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are notes on trend line adjustment, [here](http://www.fivethirtyeight.com/2008/06/we-know-more-than-we-think-big-change-2.html), [here](http://www.fivethirtyeight.com/2008/06/refinement-to-adjustment-part-i.html), [here](http://www.fivethirtyeight.com/2008/06/refinement-to-adjustment-part-ii.html), [here](http://www.fivethirtyeight.com/2008/06/trendline-now-calculated-from-daily.html), and [here](http://www.fivethirtyeight.com/2008/06/construction-season-over-technical.html). However, to the best of my knowledge, the similar state \"nearest neighbor\" clustering remains a black box."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partican Voting Index data obtained from [Wikipedia](http://en.wikipedia.org/wiki/Cook_Partisan_Voting_Index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvi = pandas.read_csv(\"/home/skipper/school/seaboldgit/talks/pydata/data/partisan_voting.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvi.set_index(\"State\", inplace=True);\n",
    "pvi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvi.PVI = pvi.PVI.replace({\"EVEN\" : \"0\"})\n",
    "pvi.PVI = pvi.PVI.str.replace(\"R\\+\", \"-\")\n",
    "pvi.PVI = pvi.PVI.str.replace(\"D\\+\", \"\")\n",
    "pvi.PVI = pvi.PVI.astype(float)\n",
    "pvi.PVI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Party affliation of electorate obtained from [Gallup](http://www.gallup.com/poll/156437/Heavily-Democratic-States-Concentrated-East.aspx#2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "party_affil = pandas.read_csv(\"/home/skipper/school/seaboldgit/talks/pydata/data/gallup_electorate.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "party_affil.Democrat = party_affil.Democrat.str.replace(\"%\", \"\").astype(float)\n",
    "party_affil.Republican = party_affil.Republican.str.replace(\"%\", \"\").astype(float)\n",
    "party_affil.set_index(\"State\", inplace=True);\n",
    "party_affil.rename(columns={\"Democrat Advantage\" : \"dem_adv\"}, inplace=True);\n",
    "party_affil[\"no_party\"] = 100 - party_affil.Democrat - party_affil.Republican"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "party_affil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_data = pandas.read_csv(\"/home/skipper/school/seaboldgit/talks/pydata/data/census_demographics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def capitalize(s):\n",
    "    s = s.title()\n",
    "    s = s.replace(\"Of\", \"of\")\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_data[\"State\"] = census_data.state.map(capitalize)\n",
    "del census_data[\"state\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_data.set_index(\"State\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loadpy https://raw.github.com/gist/3912533/d958b515f602f6e73f7b16d8bc412bc8d1f433d9/state_abbrevs.py;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_abbrev_dict = {\n",
    "        'AK': 'Alaska',\n",
    "        'AL': 'Alabama',\n",
    "        'AR': 'Arkansas',\n",
    "        'AS': 'American Samoa',\n",
    "        'AZ': 'Arizona',\n",
    "        'CA': 'California',\n",
    "        'CO': 'Colorado',\n",
    "        'CT': 'Connecticut',\n",
    "        'DC': 'District of Columbia',\n",
    "        'DE': 'Delaware',\n",
    "        'FL': 'Florida',\n",
    "        'GA': 'Georgia',\n",
    "        'GU': 'Guam',\n",
    "        'HI': 'Hawaii',\n",
    "        'IA': 'Iowa',\n",
    "        'ID': 'Idaho',\n",
    "        'IL': 'Illinois',\n",
    "        'IN': 'Indiana',\n",
    "        'KS': 'Kansas',\n",
    "        'KY': 'Kentucky',\n",
    "        'LA': 'Louisiana',\n",
    "        'MA': 'Massachusetts',\n",
    "        'MD': 'Maryland',\n",
    "        'ME': 'Maine',\n",
    "        'MI': 'Michigan',\n",
    "        'MN': 'Minnesota',\n",
    "        'MO': 'Missouri',\n",
    "        'MP': 'Northern Mariana Islands',\n",
    "        'MS': 'Mississippi',\n",
    "        'MT': 'Montana',\n",
    "        'NA': 'National',\n",
    "        'NC': 'North Carolina',\n",
    "        'ND': 'North Dakota',\n",
    "        'NE': 'Nebraska',\n",
    "        'NH': 'New Hampshire',\n",
    "        'NJ': 'New Jersey',\n",
    "        'NM': 'New Mexico',\n",
    "        'NV': 'Nevada',\n",
    "        'NY': 'New York',\n",
    "        'OH': 'Ohio',\n",
    "        'OK': 'Oklahoma',\n",
    "        'OR': 'Oregon',\n",
    "        'PA': 'Pennsylvania',\n",
    "        'PR': 'Puerto Rico',\n",
    "        'RI': 'Rhode Island',\n",
    "        'SC': 'South Carolina',\n",
    "        'SD': 'South Dakota',\n",
    "        'TN': 'Tennessee',\n",
    "        'TX': 'Texas',\n",
    "        'UT': 'Utah',\n",
    "        'VA': 'Virginia',\n",
    "        'VI': 'Virgin Islands',\n",
    "        'VT': 'Vermont',\n",
    "        'WA': 'Washington',\n",
    "        'WI': 'Wisconsin',\n",
    "        'WV': 'West Virginia',\n",
    "        'WY': 'Wyoming'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Campaign Contributions from FEC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obama_give = pandas.read_csv(\"/home/skipper/school/seaboldgit/talks/pydata/data/obama_indiv_state.csv\", \n",
    "                             header=None, names=[\"State\", \"obama_give\"])\n",
    "romney_give = pandas.read_csv(\"/home/skipper/school/seaboldgit/talks/pydata/data/romney_indiv_state.csv\",\n",
    "                             header=None, names=[\"State\", \"romney_give\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obama_give.State.replace(states_abbrev_dict, inplace=True);\n",
    "romney_give.State.replace(states_abbrev_dict, inplace=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obama_give.set_index(\"State\", inplace=True)\n",
    "romney_give.set_index(\"State\", inplace=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_data = census_data.join(party_affil[[\"dem_adv\", \"no_party\"]]).join(pvi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_data = demo_data.join(obama_give).join(romney_give)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "giving = demo_data[[\"obama_give\", \"romney_give\"]].div(demo_data[[\"vote_pop\", \"older_pop\"]].sum(1), axis=0)\n",
    "giving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_data[[\"obama_give\", \"romney_give\"]] = giving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import cluster as sp_cluster\n",
    "from sklearn import cluster, neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data = sp_cluster.vq.whiten(demo_data.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data.var(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN = neighbors.NearestNeighbors(n_neighbors=7)\n",
    "KNN.fit(clean_data)\n",
    "KNN.kneighbors(clean_data[0], return_distance=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = _[1]\n",
    "demo_data.index[0], demo_data.index[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nearest_neighbor = {}\n",
    "for i, state in enumerate(demo_data.index):\n",
    "    neighborhood = KNN.kneighbors(clean_data[i], return_distance=True)\n",
    "    nearest_neighbor.update({state : (demo_data.index[neighborhood[1]],\n",
    "                                     neighborhood[0])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nearest_neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_means = cluster.KMeans(n_clusters=5, n_init=50)\n",
    "k_means.fit(clean_data)\n",
    "values = k_means.cluster_centers_.squeeze()\n",
    "labels = k_means.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = sp_cluster.vq.kmeans(clean_data, 5)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_group(data, clusters):\n",
    "    \"\"\"\n",
    "    Return the index of the cluster to which the rows in data\n",
    "    are \"closest\" (in the sense of the L2-norm)\n",
    "    \"\"\"\n",
    "    data = data[:,None] # add an axis for broadcasting\n",
    "    distances = data - clusters\n",
    "    groups = []\n",
    "    for row in distances:\n",
    "        dists = map(np.linalg.norm, row)\n",
    "        groups.append(np.argmin(dists))\n",
    "    return groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = choose_group(clean_data, clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or use a one-liner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = [np.argmin(map(np.linalg.norm, (clean_data[:,None] - clusters)[i])) for i in range(51)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_data[\"kmeans_group\"] = groups\n",
    "demo_data[\"kmeans_labels\"] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, group in demo_data.groupby(\"kmeans_group\"):\n",
    "    group = group.index\n",
    "    group.values.sort()\n",
    "    print group.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_data[\"kmeans_labels\"] = labels\n",
    "for _, group in demo_data.groupby(\"kmeans_labels\"):\n",
    "    group = group.index.copy()\n",
    "    group.values.sort()\n",
    "    print group.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_data = demo_data.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_data2012.State.replace(states_abbrev_dict, inplace=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_data2012 = state_data2012.merge(demo_data[[\"State\", \"kmeans_labels\"]], on=\"State\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_groups = state_data2012.groupby(\"kmeans_labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = kmeans_groups.get_group(kmeans_groups.groups.keys()[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group.State.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edit_tick_label(tick_val, tick_pos):\n",
    "    if tick_val  < 0:\n",
    "        text = str(int(tick_val)).replace(\"-\", \"Romney+\")\n",
    "    else:\n",
    "        text = \"Obama+\"+str(int(tick_val))\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import lib\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "fig, axes = plt.subplots(figsize=(12,8))\n",
    "\n",
    "data = group[[\"poll_date\", \"obama_spread\"]]\n",
    "data = pandas.concat((data, national_data2012[[\"poll_date\", \"obama_spread\"]]))\n",
    "    \n",
    "data.sort(\"poll_date\", inplace=True)\n",
    "dates = pandas.DatetimeIndex(data.poll_date).asi8\n",
    "\n",
    "loess_res = sm.nonparametric.lowess(data.obama_spread.values, dates, \n",
    "                                    frac=.2, it=3)\n",
    "\n",
    "dates_x = lib.ints_to_pydatetime(dates)\n",
    "axes.scatter(dates_x, data[\"obama_spread\"])\n",
    "axes.plot(dates_x, loess_res[:,1], color='r')\n",
    "axes.yaxis.get_major_locator().set_params(nbins=12)\n",
    "axes.yaxis.set_major_formatter(FuncFormatter(edit_tick_label))\n",
    "axes.grid(False, axis='x')\n",
    "axes.hlines(0, dates_x[0], dates_x[-1], color='black', lw=3)\n",
    "axes.margins(0, .05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loess_res[-7:,1].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import lib\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "fig, axes = plt.subplots(figsize=(12,8))\n",
    "\n",
    "national_data2012.sort(\"poll_date\", inplace=True)\n",
    "dates = pandas.DatetimeIndex(national_data2012.poll_date).asi8\n",
    "\n",
    "loess_res = sm.nonparametric.lowess(national_data2012.obama_spread.values, dates, \n",
    "                                    frac=.075, it=3)\n",
    "\n",
    "dates_x = lib.ints_to_pydatetime(dates)\n",
    "axes.scatter(dates_x, national_data2012[\"obama_spread\"])\n",
    "axes.plot(dates_x, loess_res[:,1], color='r')\n",
    "axes.yaxis.get_major_locator().set_params(nbins=12)\n",
    "axes.yaxis.set_major_formatter(FuncFormatter(edit_tick_label))\n",
    "axes.grid(False, axis='x')\n",
    "axes.hlines(0, dates_x[0], dates_x[-1], color='black', lw=3)\n",
    "axes.margins(0, .05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trends = []\n",
    "for i, group in kmeans_groups:\n",
    "    data = group[[\"poll_date\", \"obama_spread\"]]\n",
    "    data = pandas.concat((data, national_data2012[[\"poll_date\", \"obama_spread\"]]))\n",
    "    \n",
    "    data.sort(\"poll_date\", inplace=True)\n",
    "    dates = pandas.DatetimeIndex(data.poll_date).asi8\n",
    "\n",
    "    loess_res = sm.nonparametric.lowess(data.obama_spread.values, dates, \n",
    "                                    frac=.1, it=3)\n",
    "    states = group.State.unique()\n",
    "    for state in states:\n",
    "        trends.append([state, loess_res[-7:,1].mean()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trends"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adjust for sensitivity to time-trends"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\text{Margin}=X_i+Z_t+\\epsilon$$\n",
    "\n",
    "where $S_i$ are Pollster:State dummies. In a state with a time-dependent trend, you might write\n",
    "\n",
    "$$\\text{Margin}=X_i+m*Z_t$$\n",
    "\n",
    "where $m$ is a multiplier representing uncertainty in the time-trend parameter. Solving for $m$ gives\n",
    "\n",
    "$$m=\\text{Margin}-\\frac{X_i}{Z_t}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.formula.api import ols, wls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pollster_state_dummy = state_data2012.groupby([\"Pollster\", \"State\"])[\"obama_spread\"].mean()\n",
    "#daily_dummy = state_data2012.groupby([\"poll_date\"])[\"obama_spread\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_data2012[\"pollster_state\"] = state_data2012[\"Pollster\"] + \"-\" + state_data2012[\"State\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's actually a bug in pandas when you merge on datetimes. In order to avoid it, we need to sort our data now and once again after we merge on dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_data2012.sort(columns=[\"pollster_state\", \"poll_date\"], inplace=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_model = ols(\"obama_spread ~ C(pollster_state) + C(poll_date)\", data=state_data2012).fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The base case is American Research Group-Colorado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_data2012.irow(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pollster_state = state_data2012[\"pollster_state\"].unique()\n",
    "pollster_state.sort()\n",
    "pollster_state_params = dummy_model.params[1:len(pollster_state)] + dummy_model.params[0]\n",
    "intercept = dummy_model.params[0]\n",
    "X = pandas.DataFrame(zip(pollster_state, np.r_[intercept, pollster_state_params]), \n",
    "                     columns=[\"pollster_state\", \"X\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = state_data2012.poll_date.unique()\n",
    "dates.sort()\n",
    "dates_params = intercept + dummy_model.params[-len(dates):]\n",
    "Z = pandas.DataFrame(zip(dates, dates_params), columns=[\"poll_date\", \"Z\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop the ones less than 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = Z.ix[np.abs(Z.Z) > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_data2012 = state_data2012.merge(X, on=\"pollster_state\", sort=False)\n",
    "state_data2012 = state_data2012.merge(Z, on=\"poll_date\", sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_data2012.sort(columns=[\"pollster_state\", \"poll_date\"], inplace=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_data2012[\"m\"] = state_data2012[\"obama_spread\"].sub(state_data2012[\"X\"].div(state_data2012[\"Z\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#m_dataframe.ix[m_dataframe.pollster_state == \"American Research Group-New Hampshire\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_dataframe = state_data2012[[\"State\", \"m\", \"poll_date\", \"Pollster\", \"pollster_state\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_dataframe[\"m\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_size = m_dataframe.groupby(\"pollster_state\").size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_idx = m_size.ix[m_size == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_dataframe = m_dataframe.set_index([\"pollster_state\", \"poll_date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_dataframe.xs(\"American Research Group-New Hampshire\", level=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_dataframe = m_dataframe.drop(drop_idx.index, level=0).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_regression_data = m_dataframe.merge(demo_data, on=\"State\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_regression_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_regression_data[[\"PVI\", \"per_black\", \"per_hisp\", \"older_pop\", \"average_income\", \n",
    "                   \"romney_give\", \"obama_give\", \"educ_coll\", \"educ_hs\"]].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(today - m_regression_data[\"poll_date\"].astype('O'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_weights = (today - m_regression_data[\"poll_date\"].astype('O')).apply(exp_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_model = wls(\"m ~ PVI + per_hisp + per_black + average_income + educ_coll\", data=m_regression_data, weights=time_weights).fit()\n",
    "m_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_resid = pandas.DataFrame(zip(m_model.resid, m_regression_data.State), \n",
    "                               columns=[\"resid\", \"State\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_resid_group = state_resid.groupby(\"State\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize=(12,8), subplot_kw={\"ylabel\" : \"Residual\",\n",
    "                                                     \"xlabel\" : \"State\"})\n",
    "i = 0\n",
    "for state, group in state_resid_group:\n",
    "    x = [i] * len(group)\n",
    "    axes.scatter(x, group[\"resid\"], s=91)\n",
    "    i += 1\n",
    "states = m_regression_data.State.unique()\n",
    "states.sort()\n",
    "#axes.xaxis.get_major_locator().set_params(nbins=len(states))\n",
    "axes.margins(.05, .05)\n",
    "axes.xaxis.set_ticks(range(31))\n",
    "axes.xaxis.set_ticklabels(states);\n",
    "for label in axes.xaxis.get_ticklabels():\n",
    "    label.set_rotation(90)\n",
    "    label.set_fontsize('large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_data = demo_data.drop(demo_data.index[demo_data['State'] == 'District of Columbia'])\n",
    "demo_data.reset_index(drop=True, inplace=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exog = demo_data[[\"PVI\", \"per_hisp\", \"per_black\", \"average_income\", \"educ_coll\"]]\n",
    "exog[\"const\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_m = m_model.predict(exog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_m = (state_m - state_m.min())/(state_m.max() - state_m.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_m *= 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_correction = zip(demo_data.State, unit_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize=(12,8), subplot_kw={\"ylabel\" : \"Time Uncertainty\",\n",
    "                                                     \"xlabel\" : \"State\"})\n",
    "\n",
    "axes.scatter(range(len(unit_m)), unit_m, s=91)\n",
    "\n",
    "axes.margins(.05, .05)\n",
    "axes.xaxis.set_ticks(range(len(unit_m)))\n",
    "axes.xaxis.set_ticklabels(demo_data.State);\n",
    "for label in axes.xaxis.get_ticklabels():\n",
    "    label.set_rotation(90)\n",
    "    label.set_fontsize('large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trends = pandas.DataFrame(trends, columns=[\"State\", \"trend\"])\n",
    "m_correction = pandas.DataFrame(m_correction, columns=[\"State\", \"m_correction\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trends = trends.merge(m_correction, on=\"State\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trends.set_index(\"State\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trends = trends.product(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Snapshot: Combine Trend Estimates and State Polls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_polls.name = \"poll\"\n",
    "state_polls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_polls = state_polls.reset_index()\n",
    "state_polls.State = state_polls.State.replace(states_abbrev_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trends.name = \"poll\"\n",
    "trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trends = trends.reset_index()\n",
    "trends[\"Pollster\"] = \"National\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polls = pandas.concat((state_polls, trends))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "natl_weight = pandas.DataFrame([[\"National\", weights.Weight.mean(), weights.PIE.mean()]],\n",
    "                                columns=[\"Pollster\", \"Weight\", \"PIE\"])\n",
    "weights = pandas.concat((weights, natl_weight)).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polls = polls.merge(weights, on=\"Pollster\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polls = polls.sort(\"State\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_mean(group):\n",
    "    return (group[\"poll\"] * group[\"Weight\"] / group[\"Weight\"].sum()).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = polls.groupby(\"State\").aggregate(weighted_mean)[\"poll\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = results.reset_index()\n",
    "results[\"obama\"] = 0\n",
    "results[\"romney\"] = 0\n",
    "results.ix[results[\"poll\"] > 0, [\"obama\"]] = 1\n",
    "results.ix[results[\"poll\"] < 0, [\"romney\"]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[[\"State\", \"poll\"]].to_csv(\"/home/skipper/school/talks/538model/2012-predicted.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "electoral_votes = pandas.read_csv(\"/home/skipper/school/seaboldgit/talks/pydata/data/electoral_votes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "electoral_votes.sort(\"State\", inplace=True).reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = electoral_votes.merge(results, on=\"State\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = results.set_index(\"State\")\n",
    "red_states = [\"Alabama\", \"Alaska\", \"Arkansas\", \"Idaho\", \"Kentucky\", \"Louisiana\",\n",
    "              \"Oklahoma\", \"Wyoming\"]\n",
    "blue_states = [\"Delaware\", \"District of Columbia\"]\n",
    "results.ix[red_states, [\"romney\"]] = 1\n",
    "results.ix[red_states, [\"obama\"]] = 0\n",
    "results.ix[blue_states, [\"obama\"]] = 1\n",
    "results.ix[blue_states, [\"romney\"]] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[\"Votes\"].mul(results[\"obama\"]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[\"Votes\"].mul(results[\"romney\"]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divide undecided voters probabilistically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do historical adjustments based on how polls changed in the past conditional on \"election environment\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Error analysis\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
