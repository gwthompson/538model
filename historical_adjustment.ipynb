{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "from scipy import stats\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "pandas.set_option('notebook_repr_html', False)\n",
    "pandas.set_option('precision', 4)\n",
    "pandas.set_option('max_columns', 12)\n",
    "pandas.set_option('column_space',10)\n",
    "pandas.set_option('max_colwidth',25)\n",
    "\n",
    "#pandas.set_printoptions(notebook_repr_html=False,\n",
    "#                        precision=4,\n",
    "#                        max_columns=12, column_space=10,\n",
    "#                        max_colwidth=25)\n",
    "from matplotlib import rcParams\n",
    "#rcParams['text.usetex'] = False\n",
    "#rcParams['text.latex.unicode'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a snapshot for what would happen if the election is held today (Don't go bet on intratrade based on this model). Historically, polls have narrowed as the election nears."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up some globals for dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = datetime.datetime(2012, 10, 2)\n",
    "election = datetime.datetime(2012, 11, 6)\n",
    "days_before = election - today\n",
    "date2004 = datetime.datetime(2004, 11, 2)\n",
    "days_before2004 = date2004 - days_before\n",
    "date2008 = datetime.datetime(2008, 11, 4)\n",
    "days_before2008 = date2008 - days_before"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: Put a basemap map here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load that data and clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "national_2004 = pandas.read_csv(\"data/2004_poll_data.csv\")\n",
    "national_2004.rename(columns={\"Poll\" : \"Pollster\"}, inplace=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_data2004 = pandas.read_csv(\"data/2004-pres-polls.csv\")\n",
    "state_data2008 = pandas.read_csv(\"data/2008-pres-polls.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    State  Kerry  Bush    Date                Pollster\n",
       "0      AL     39    57  Oct 25               SurveyUSA\n",
       "1      AL     32    56  Oct 12          Capital Survey\n",
       "2      AL     34    62  Oct 01               SurveyUSA\n",
       "3      AL     40    54  Sep 14                     ARG\n",
       "4      AL     42    53  Sep 06               Rasmussen\n",
       "5      AL     37    58  Aug 23              Survey USA\n",
       "6      AL     34    51  Aug 12          Capital Survey\n",
       "7      AL     34    56  Jul 28          Capital Survey\n",
       "8      AL     38    52  Jun 30               Rasmussen\n",
       "9      AL     35    54  May 27          Capital Survey\n",
       "10     AK     30    57  Sep 09                     ARG\n",
       "11     AK     33    56  Jun 30        Dittman Research\n",
       "12     AZ     41    56  Oct 28               SurveyUSA\n",
       "13     AZ     45    50  Oct 19     Arizona State Univ.\n",
       "14     AZ     40    47  Oct 18        Market Solutions\n",
       "15     AZ     43    54  Oct 17               SurveyUSA\n",
       "16     AZ     47    50  Oct 15                   Zogby\n",
       "17     AZ     44    49  Oct 09  Northern Arizona Univ.\n",
       "18     AZ     41    55  Oct 05                  Survey\n",
       "19     AZ     38    48  Oct 02     Arizona State Univ.\n",
       "20     AZ     47    50  Oct 02                   Zogby\n",
       "21     AZ     44    53  Sep 27               SurveyUSA\n",
       "22     AZ     38    49  Sep 24     Arizona State Univ.\n",
       "23     AZ     43    54  Sep 21               SurveyUSA\n",
       "24     AZ     48    49  Sep 14                   Zogby\n",
       "25     AZ     39    50  Sep 13             Mason-Dixon\n",
       "26     AZ     43    49  Sep 12                     ARG\n",
       "27     AZ     45    48  Aug 01        Market Solutions\n",
       "28     AZ     36    48  Jul 14              Survey USA\n",
       "29     AZ     41    44  Jun 19        Market Solutions\n",
       "..    ...    ...   ...     ...                     ...\n",
       "849    WI     48    46  Oct 24                   Zogby\n",
       "850    WI     43    51  Oct 17                  Gallup\n",
       "851    WI     47    47  Oct 17                     ARG\n",
       "852    WI     45    45  Oct 16             Mason-Dixon\n",
       "853    WI     47    48  Oct 16             Univ. of MN\n",
       "854    WI     51    48  Oct 15                   Zogby\n",
       "855    WI     47    43  Oct 09           Market Shares\n",
       "856    WI     48    43  Oct 08        St. Norbert Coll\n",
       "857    WI     45    48  Oct 03                  Gallup\n",
       "858    WI     51    48  Oct 02                   Zogby\n",
       "859    WI     40    50  Sep 23                  Harris\n",
       "860    WI     45    51  Sep 20                   IPSOS\n",
       "861    WI     38    52  Sep 17             Badger Poll\n",
       "862    WI     44    50  Sep 17                ABC News\n",
       "863    WI     44    46  Sep 14             Mason-Dixon\n",
       "864    WI     50    48  Sep 14                   Zogby\n",
       "865    WI     46    46  Sep 13                     ARG\n",
       "866    WI     44    52  Sep 10                  Gallup\n",
       "867    WI     44    48  Aug 24                LA Times\n",
       "868    WI     51    46  Aug 21                   Zogby\n",
       "869    WI     50    48  Jul 30                   Zogby\n",
       "870    WI     50    46  Jul 23                   Zogby\n",
       "871    WI     48    42  Jul 15                     ARG\n",
       "872    WI     45    46  Jul 12    Hubert Humphrey Inst\n",
       "873    WI     53    44  Jul 10                   Zogby\n",
       "874    WI     42    46  Jun 23                  Badger\n",
       "875    WI     51    46  Jun 20                   Zogby\n",
       "876    WI     42    44  Jun 08                LA Times\n",
       "877    WI     52    44  May 23                   Zogby\n",
       "878    WY     29    65  Sep 09                     ARG\n",
       "\n",
       "[879 rows x 5 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_data2004"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_data2004.rename(columns={\"Kerry\" : \"challenger\", \n",
    "                               \"Bush\" : \"incumbent\"}, \n",
    "                      inplace=True);\n",
    "state_data2004[\"dem_spread\"] = (state_data2004[\"challenger\"] - \n",
    "                                      state_data2004[\"incumbent\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      Oct 25, 2004\n",
      "1      Oct 12, 2004\n",
      "2      Oct 01, 2004\n",
      "3      Sep 14, 2004\n",
      "4      Sep 06, 2004\n",
      "5      Aug 23, 2004\n",
      "6      Aug 12, 2004\n",
      "7      Jul 28, 2004\n",
      "8      Jun 30, 2004\n",
      "9      May 27, 2004\n",
      "10     Sep 09, 2004\n",
      "11     Jun 30, 2004\n",
      "12     Oct 28, 2004\n",
      "13     Oct 19, 2004\n",
      "14     Oct 18, 2004\n",
      "15     Oct 17, 2004\n",
      "16     Oct 15, 2004\n",
      "17     Oct 09, 2004\n",
      "18     Oct 05, 2004\n",
      "19     Oct 02, 2004\n",
      "20     Oct 02, 2004\n",
      "21     Sep 27, 2004\n",
      "22     Sep 24, 2004\n",
      "23     Sep 21, 2004\n",
      "24     Sep 14, 2004\n",
      "25     Sep 13, 2004\n",
      "26     Sep 12, 2004\n",
      "27     Aug 01, 2004\n",
      "28     Jul 14, 2004\n",
      "29     Jun 19, 2004\n",
      "           ...     \n",
      "849    Oct 24, 2004\n",
      "850    Oct 17, 2004\n",
      "851    Oct 17, 2004\n",
      "852    Oct 16, 2004\n",
      "853    Oct 16, 2004\n",
      "854    Oct 15, 2004\n",
      "855    Oct 09, 2004\n",
      "856    Oct 08, 2004\n",
      "857    Oct 03, 2004\n",
      "858    Oct 02, 2004\n",
      "859    Sep 23, 2004\n",
      "860    Sep 20, 2004\n",
      "861    Sep 17, 2004\n",
      "862    Sep 17, 2004\n",
      "863    Sep 14, 2004\n",
      "864    Sep 14, 2004\n",
      "865    Sep 13, 2004\n",
      "866    Sep 10, 2004\n",
      "867    Aug 24, 2004\n",
      "868    Aug 21, 2004\n",
      "869    Jul 30, 2004\n",
      "870    Jul 23, 2004\n",
      "871    Jul 15, 2004\n",
      "872    Jul 12, 2004\n",
      "873    Jul 10, 2004\n",
      "874    Jun 23, 2004\n",
      "875    Jun 20, 2004\n",
      "876    Jun 08, 2004\n",
      "877    May 23, 2004\n",
      "878    Sep 09, 2004\n",
      "Name: Date, Length: 879, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(state_data2004.Date + \", 2004\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'pandas' has no attribute 'datetools'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-27ed42fadaec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m                             inplace=True);\n\u001b[1;32m      3\u001b[0m state_data2004.Date = (state_data2004.Date + \", 2004\").apply(\n\u001b[0;32m----> 4\u001b[0;31m                                                 pandas.datetools.parse)\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'pandas' has no attribute 'datetools'"
     ]
    }
   ],
   "source": [
    "state_data2004.Date.replace({\"Nov 00\" : \"Nov 01\", \"Oct 00\" : \"Oct 01\"}, \n",
    "                            inplace=True);\n",
    "state_data2004.Date = (state_data2004.Date + \", 2004\").apply(\n",
    "                                                pandas.datetools.parse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def median_date(row, year=\"2008\"):\n",
    "    dt1 = pandas.datetools.parse(row[\"Start\"] + \", \" + year)\n",
    "    dt2 = pandas.datetools.parse(row[\"End\"] + \", \" + year)\n",
    "    dates = pandas.date_range(dt1, dt2)\n",
    "    median_idx = int(np.median(range(len(dates)))+.5)\n",
    "    return dates[median_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_data2008[\"Date\"] = state_data2008.apply(median_date, axis=1)\n",
    "del state_data2008[\"Start\"]\n",
    "del state_data2008[\"End\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual = national_2004.head(1)\n",
    "national_2004 = national_2004.ix[national_2004.index[~national_2004.Pollster.isin([\"Final Results\", \"RCP Average\"])]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_median_date(row):\n",
    "    dt = row[\"Date\"]\n",
    "    dt1, dt2 = dt.split(\" - \")\n",
    "    dates = pandas.date_range(dt1 + \", 2004\", dt2 + \", 2004\")\n",
    "    median_idx = int(np.median(range(len(dates)))+.5)\n",
    "    return dates[median_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "national_2004[\"Date\"] = national_2004.apply(split_median_date, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "national_2004[\"dem_spread\"] = national_2004[\"Kerry (D)\"] - national_2004[\"Bush (R)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_data2008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_data2008.rename(columns={\"Obama\" : \"challenger\", \n",
    "                               \"McCain\" : \"incumbent\"}, \n",
    "                      inplace=True);\n",
    "state_data2008[\"dem_spread\"] = (state_data2008[\"challenger\"] - \n",
    "                                      state_data2008[\"incumbent\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean the Pollster names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pollster_map = pickle.load(open(\n",
    "                 \"/home/skipper/school/talks/538model/data/pollster_map.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_data2004.Pollster.replace(pollster_map, inplace=True);\n",
    "state_data2008.Pollster.replace(pollster_map, inplace=True);\n",
    "national_2004.Pollster.replace(pollster_map, inplace=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the Pollster weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are old weights obtained from the 538 web site. New weights are not published anywhere to my knowledge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = pandas.read_table(\"/home/skipper/school/talks/538model/\"\n",
    "                            \"data/pollster_weights.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_data2004 = state_data2004.merge(weights, on=\"Pollster\", how=\"inner\");\n",
    "state_data2008 = state_data2008.merge(weights, on=\"Pollster\", how=\"inner\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's the Assertion?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edit_tick_label(tick_val, tick_pos):\n",
    "    if tick_val  < 0:\n",
    "        text = str(int(tick_val)).replace(\"-\", \"Republican+\")\n",
    "    else:\n",
    "        text = \"Democrat+\"+str(int(tick_val))\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import lib\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "fig, axes = plt.subplots(figsize=(12,8))\n",
    "\n",
    "data = national_2004[[\"Date\", \"dem_spread\"]]\n",
    "#data = data.ix[data.Date >= days_before2004]\n",
    "#data = pandas.concat((data, national_data2012[[\"Date\", \"dem_spread\"]]))\n",
    "    \n",
    "data.sort(\"Date\", inplace=True)\n",
    "dates = pandas.DatetimeIndex(data.Date).asi8\n",
    "\n",
    "x = data.dem_spread.values.astype(float)\n",
    "lowess_res = sm.nonparametric.lowess(x, dates, \n",
    "                                    frac=.2, it=3)[:,1]\n",
    "\n",
    "dates_x = lib.ints_to_pydatetime(dates)\n",
    "axes.scatter(dates_x, data[\"dem_spread\"])\n",
    "axes.plot(dates_x, lowess_res, color='r', lw=4)\n",
    "axes.yaxis.get_major_locator().set_params(nbins=12)\n",
    "axes.yaxis.set_major_formatter(FuncFormatter(edit_tick_label))\n",
    "axes.grid(False, axis='x')\n",
    "axes.hlines(-1.21, dates_x[0], dates_x[-1], color='black', lw=3)\n",
    "axes.vlines(datetime.datetime(2004, 8, 5), -20, 15, lw=3)\n",
    "axes.margins(0, .00)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's look at the State Polls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import lib\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "fig, axes = plt.subplots(figsize=(12,8))\n",
    "\n",
    "data = state_data2004[[\"Date\", \"dem_spread\"]]\n",
    "#data = data.ix[data.Date >= days_before2004]\n",
    "data = data.ix[data.Date >= datetime.datetime(2004, 7, 15)]\n",
    "#data = pandas.concat((data, national_data2012[[\"Date\", \"dem_spread\"]]))\n",
    "    \n",
    "data.sort(\"Date\", inplace=True)\n",
    "dates = pandas.DatetimeIndex(data.Date).asi8\n",
    "\n",
    "x = data.dem_spread.values.astype(float)\n",
    "lowess_res = sm.nonparametric.lowess(x, dates, \n",
    "                                    frac=.2, it=3)[:,1]\n",
    "\n",
    "dates_x = lib.ints_to_pydatetime(dates)\n",
    "axes.scatter(dates_x, data[\"dem_spread\"])\n",
    "axes.plot(dates_x, lowess_res, color='r', lw=4)\n",
    "axes.yaxis.get_major_locator().set_params(nbins=12)\n",
    "axes.yaxis.set_major_formatter(FuncFormatter(edit_tick_label))\n",
    "axes.grid(False, axis='x')\n",
    "axes.hlines(-1.21, dates_x[0], dates_x[-1], color='black', lw=3)\n",
    "axes.margins(0, .05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import lib\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "fig, axes = plt.subplots(figsize=(12,8))\n",
    "\n",
    "data = state_data2008[[\"Date\", \"dem_spread\"]]\n",
    "data = data.ix[data.Date >= datetime.datetime(2008, 7, 15)]\n",
    "#data = data.ix[data.Date >= days_before2008]\n",
    "#data = pandas.concat((data, national_data2012[[\"Date\", \"dem_spread\"]]))\n",
    "    \n",
    "data.sort(\"Date\", inplace=True)\n",
    "dates = pandas.DatetimeIndex(data.Date).asi8\n",
    "\n",
    "x = data.dem_spread.values.astype(float)\n",
    "lowess_res = sm.nonparametric.lowess(x, dates, \n",
    "                                    frac=.2, it=3)[:,1]\n",
    "\n",
    "dates_x = lib.ints_to_pydatetime(dates)\n",
    "axes.scatter(dates_x, data[\"dem_spread\"])\n",
    "axes.plot(dates_x, lowess_res, color='r', lw=4)\n",
    "axes.yaxis.get_major_locator().set_params(nbins=12)\n",
    "axes.yaxis.set_major_formatter(FuncFormatter(edit_tick_label))\n",
    "axes.grid(False, axis='x')\n",
    "axes.hlines(3.65, dates_x[0], dates_x[-1], color='black', lw=3)\n",
    "axes.vlines(datetime.datetime(2008, 8, 29), -45, 70, lw=3)\n",
    "axes.vlines(datetime.datetime(2008, 9, 24), -45, 70, lw=3)\n",
    "axes.margins(0, .0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loadpy https://raw.github.com/gist/3912533/d958b515f602f6e73f7b16d8bc412bc8d1f433d9/state_abbrevs.py;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_abbrev_dict = {\n",
    "        'AK': 'Alaska',\n",
    "        'AL': 'Alabama',\n",
    "        'AR': 'Arkansas',\n",
    "        'AS': 'American Samoa',\n",
    "        'AZ': 'Arizona',\n",
    "        'CA': 'California',\n",
    "        'CO': 'Colorado',\n",
    "        'CT': 'Connecticut',\n",
    "        'DC': 'District of Columbia',\n",
    "        'DE': 'Delaware',\n",
    "        'FL': 'Florida',\n",
    "        'GA': 'Georgia',\n",
    "        'GU': 'Guam',\n",
    "        'HI': 'Hawaii',\n",
    "        'IA': 'Iowa',\n",
    "        'ID': 'Idaho',\n",
    "        'IL': 'Illinois',\n",
    "        'IN': 'Indiana',\n",
    "        'KS': 'Kansas',\n",
    "        'KY': 'Kentucky',\n",
    "        'LA': 'Louisiana',\n",
    "        'MA': 'Massachusetts',\n",
    "        'MD': 'Maryland',\n",
    "        'ME': 'Maine',\n",
    "        'MI': 'Michigan',\n",
    "        'MN': 'Minnesota',\n",
    "        'MO': 'Missouri',\n",
    "        'MP': 'Northern Mariana Islands',\n",
    "        'MS': 'Mississippi',\n",
    "        'MT': 'Montana',\n",
    "        'NA': 'National',\n",
    "        'NC': 'North Carolina',\n",
    "        'ND': 'North Dakota',\n",
    "        'NE': 'Nebraska',\n",
    "        'NH': 'New Hampshire',\n",
    "        'NJ': 'New Jersey',\n",
    "        'NM': 'New Mexico',\n",
    "        'NV': 'Nevada',\n",
    "        'NY': 'New York',\n",
    "        'OH': 'Ohio',\n",
    "        'OK': 'Oklahoma',\n",
    "        'OR': 'Oregon',\n",
    "        'PA': 'Pennsylvania',\n",
    "        'PR': 'Puerto Rico',\n",
    "        'RI': 'Rhode Island',\n",
    "        'SC': 'South Carolina',\n",
    "        'SD': 'South Dakota',\n",
    "        'TN': 'Tennessee',\n",
    "        'TX': 'Texas',\n",
    "        'UT': 'Utah',\n",
    "        'VA': 'Virginia',\n",
    "        'VI': 'Virgin Islands',\n",
    "        'VT': 'Vermont',\n",
    "        'WA': 'Washington',\n",
    "        'WI': 'Wisconsin',\n",
    "        'WV': 'West Virginia',\n",
    "        'WY': 'Wyoming'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_data2004.State.replace(states_abbrev_dict, inplace=True);\n",
    "state_data2008.State.replace(states_abbrev_dict, inplace=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_data2004[\"days_until\"] = date2004 - state_data2004.Date\n",
    "state_data2008[\"days_until\"] = date2008 - state_data2004.Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#state_data2004 = state_data2004.drop(\n",
    "#                    state_data2004.index[state_data2004.days_until > days_before])\n",
    "#state_data2008 = state_data2008.drop(\n",
    "#                    state_data2008.index[state_data2008.days_until > days_before])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp_decay(days):\n",
    "    # defensive coding, accepts timedeltas\n",
    "    days = getattr(days, \"days\", days)\n",
    "    return .5 ** (days/30.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_data2004[\"time_weight_oct2\"] = (days_before2004 - \n",
    "                                      state_data2004[\"Date\"]).apply(exp_decay)\n",
    "state_data2004[\"time_weight_election\"] = (date2004 -\n",
    "                                      state_data2004[\"Date\"]).apply(exp_decay)\n",
    "state_data2008[\"time_weight_oct2\"] = (days_before2008 - \n",
    "                                      state_data2008[\"Date\"]).apply(exp_decay)\n",
    "state_data2008[\"time_weight_election\"] = (date2008 -\n",
    "                                      state_data2008[\"Date\"]).apply(exp_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_mean(group, weights_name):\n",
    "    weights = group[weights_name]\n",
    "    return np.sum(weights*group[\"dem_spread\"]/np.sum(weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get weighted average State-level polls for Oct 2 and Election Day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_state_averages(dframe, time_weight_name):\n",
    "    dframe_pollsters = dframe.groupby([\"State\", \"Pollster\"])\n",
    "    dframe_result = dframe_pollsters.apply(weighted_mean, time_weight_name)\n",
    "    dframe_result.name = \"dem_spread\"\n",
    "    dframe_result = dframe_result.reset_index()\n",
    "    dframe_result = dframe_result.merge(dframe[[\"Pollster\", \"Weight\"]],\n",
    "                          on=\"Pollster\")\n",
    "    return dframe_result.groupby(\"State\").apply(weighted_mean, \"Weight\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oct2 = state_data2004.Date <= days_before2004\n",
    "state_polls_oct2_2004 = get_state_averages(state_data2004.ix[oct2], \"time_weight_oct2\")\n",
    "state_polls_election_2004 = get_state_averages(state_data2004, \"time_weight_election\")\n",
    "updated2004 = state_data2004.ix[~oct2].State.unique()\n",
    "updated2004.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oct2 = state_data2008.Date <= days_before2008\n",
    "state_polls_oct2_2008 = get_state_averages(state_data2008.ix[oct2], \"time_weight_oct2\")\n",
    "state_polls_election_2008 = get_state_averages(state_data2008, \"time_weight_election\")\n",
    "updated2008 = state_data2008.ix[~oct2].State.unique()\n",
    "updated2008.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Economic Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "    <thead>\n",
    "        <tr style=\"background: black; color: white; text-align: center\">\n",
    "            <th style=\"padding: 15px; border-right-color: white; text-align: center\">FRED Variable</th>\n",
    "            <th style=\"padding: 15px; border-left-color: white; text-align: center\">Explanation</th>\n",
    "        </tr>\n",
    "    </thead>\n",
    "    <tbody>\n",
    "        <tr>\n",
    "            <td><b>PAYEMS</b></td>\n",
    "            <td>Nonfarm-Payrolls (Job Growth)</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td><b>PI</b></td>\n",
    "            <td>Personal Income</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td><b>INDPRO</b></td>\n",
    "            <td>Industrial Production</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td><b>PCEC96</b></td>\n",
    "            <td>Consumption</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td><b>CPIAUCSL</b></td>\n",
    "            <td>Inflation</td>\n",
    "        </tr>\n",
    "    </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.io.data import DataReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = dict(jobs = \"PAYEMS\",\n",
    "              income = \"PI\",\n",
    "              prod = \"INDPRO\",\n",
    "              cons = \"PCEC96\",\n",
    "              prices = \"CPIAUCSL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    indicators = []\n",
    "    for variable in series:\n",
    "        data = DataReader(series[variable], \"fred\", start=\"2000-10-1\")\n",
    "        data.rename(columns={series[variable] : variable}, inplace=True)\n",
    "        indicators.append(data)\n",
    "    indicators = pandas.concat(indicators, axis=1)\n",
    "    indicators.to_csv(\"/home/skipper/school/talks/538model/tmp_indicators_full.csv\")\n",
    "except: # probably not online\n",
    "    indicators = pandas.read_csv(\"/home/skipper/school/talks/538model/tmp_indicators_full.csv\", \n",
    "                                 parse_dates=True)\n",
    "    indicators.set_index(\"DATE\", inplace=True)\n",
    "    # why doesn't it do this automaticall?\n",
    "    indicators.index = pandas.DatetimeIndex(indicators.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For stock variables, just compute annualized quarterly growth rates (end - beginning)/beginning * 400 and average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quarterly_growth = np.log(indicators.resample(\"Q\", \n",
    "                          how=\"mean\")).diff() * 400\n",
    "annualized = quarterly_growth.resample(\"A\", how=\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quarterly_growth = quarterly_growth.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to be rigorous about what the voters know at the time of election."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "econ2004 = quarterly_growth.ix[:15].resample('A', 'mean').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "econ2008 = quarterly_growth.ix[15:31].resample('A', 'mean').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leave out last quarter 2008 because that's on Bush? Do voters see it that way...?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "econ2012 = quarterly_growth.ix[32:].resample('A', 'mean').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For flow variables, sum the quarters and get annualized quarter over quarter changes then average."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Demographic Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partisan voting index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvi = pandas.read_csv(\"/home/skipper/school/talks/538model/data/partisan_voting.csv\")\n",
    "pvi.set_index(\"State\", inplace=True);\n",
    "pvi.PVI = pvi.PVI.replace({\"EVEN\" : \"0\"})\n",
    "pvi.PVI = pvi.PVI.str.replace(\"R\\+\", \"-\")\n",
    "pvi.PVI = pvi.PVI.str.replace(\"D\\+\", \"\")\n",
    "pvi.PVI = pvi.PVI.astype(float)\n",
    "pvi.PVI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gallup party affiliation (Poll Jan.-Jun. 2012)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "party_affil = pandas.read_csv(\"/home/skipper/school/talks/538model/\"\n",
    "                              \"data/gallup_electorate.csv\")\n",
    "party_affil.Democrat = party_affil.Democrat.str.replace(\"%\", \"\").astype(float)\n",
    "party_affil.Republican = party_affil.Republican.str.replace(\"%\", \"\").astype(float)\n",
    "party_affil.set_index(\"State\", inplace=True);\n",
    "party_affil.rename(columns={\"Democrat Advantage\" : \"dem_adv\"}, inplace=True);\n",
    "party_affil[\"no_party\"] = 100 - party_affil.Democrat - party_affil.Republican\n",
    "party_affil[[\"dem_adv\", \"no_party\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Census data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_data_2012 = pandas.read_csv(\"/home/skipper/school/talks/\"\n",
    "                              \"538model/data/census_demographics.csv\")\n",
    "def capitalize(s):\n",
    "    s = s.title()\n",
    "    s = s.replace(\"Of\", \"of\")\n",
    "    return s\n",
    "census_data_2012[\"State\"] = census_data_2012.state.map(capitalize)\n",
    "del census_data_2012[\"state\"]\n",
    "census_data_2012.set_index(\"State\", inplace=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_data_2000 = pandas.read_csv(\"/home/skipper/school/talks/\"\n",
    "                                   \"538model/data/census_data_2000.csv\")\n",
    "census_data_2000.set_index(\"State\", inplace=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_data_2005 = (census_data_2000 + census_data_2012) / 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model reversion to the \"mean\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### A little more data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "changes_2004 = state_polls_election_2004.ix[updated2004].sub(\n",
    "                    state_polls_oct2_2004)\n",
    "changes_2004 = changes_2004.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "changes_2008 = state_polls_election_2008.ix[updated2008].sub(\n",
    "                    state_polls_oct2_2008)\n",
    "changes_2008 = changes_2008.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "changes_2004"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "changes_2008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in econ2004.index:\n",
    "    census_data_2000[name] = econ2004.ix[name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in econ2008.index:\n",
    "    census_data_2005[name] = econ2008.ix[name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_data_2000[\"poll_change\"] = changes_2004\n",
    "census_data_2005[\"poll_change\"] = changes_2008\n",
    "#changes_2008 = changes_2008.join(census_data_2005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#years = pandas.DataFrame([2004]*len(changes_2004), columns=[\"Year\"], index=changes_2004.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#years[\"poll_change\"] = changes_2004\n",
    "#changes_2004 = years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#years = pandas.DataFrame([2008]*len(changes_2008), columns=[\"Year\"], index=changes_2008.index)\n",
    "#years[\"poll_change\"] = changes_2008\n",
    "#changes_2008 = years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#changes_2004"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#changes_2004 = changes_2004.join(census_data_2000, how=\"left\")\n",
    "#changes_2008 = changes_2008.join(census_data_2000, how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_data_2000[\"year\"] = 2004\n",
    "census_data_2005[\"year\"] = 2008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "changes = pandas.concat((census_data_2000.reset_index(), census_data_2005.reset_index()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "changes.reset_index(drop=True, inplace=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "changes = changes.dropna() # don't have polls for all the states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = census_data_2012.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict[\"year\"] = 2012"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add in Partisan information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "changes = changes.merge(pvi.reset_index(), on=\"State\")\n",
    "predict = predict.merge(pvi.reset_index(), on=\"State\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add in Party affiliation information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "changes = changes.merge(party_affil[[\"dem_adv\", \"no_party\"]].reset_index(), on=\"State\")\n",
    "predict = predict.merge(party_affil[[\"dem_adv\", \"no_party\"]].reset_index(), on=\"State\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Do the K-means clustering for similar states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster import vq\n",
    "from sklearn import cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clstr_dta = predict[[\"per_black\", \"per_hisp\", \"per_white\", \"educ_coll\", \"pop_density\", \"per_older\", \"PVI\", \"dem_adv\"]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clstr_dta = vq.whiten(clstr_dta) # might want to play with this to emphasize dimensions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = cluster.KMeans(n_clusters=7, n_init=100)\n",
    "kmeans.fit(clstr_dta)\n",
    "values = kmeans.cluster_centers_\n",
    "labels = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict[\"kmeans_groups\"] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, grp in predict.groupby(\"kmeans_groups\"): print key, grp.State.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "changes = changes.merge(predict[[\"kmeans_groups\", \"State\"]], on=\"State\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop D.C. because it's not in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict.set_index([\"State\", \"year\"], inplace=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = predict.drop((\"District of Columbia\", 2012))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's explore some hypotheses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "changes.set_index([\"State\", \"year\"], inplace=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.formula.api import ols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "changes[[\"dem_adv\", \"PVI\"]].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = (\"poll_change ~ C(kmeans_groups) + per_older*per_white + \"\n",
    "           \"per_hisp + no_party*np.log(median_income) + PVI\")\n",
    "mod = ols(formula, data=changes).fit()\n",
    "print mod.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyp = \", \".join(mod.model.exog_names[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print hyp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print mod.f_test(hyp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted2012 = pandas.read_csv(\"/home/skipper/school/talks/538model/2012-predicted.csv\")\n",
    "predicted2012[\"year\"] = 2012\n",
    "predicted2012 = predicted2012.set_index([\"State\", \"year\"])[\"poll\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_change = pandas.Series(mod.predict(predict), index=predict.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = predicted2012 + predicted_change\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "electoral_votes = pandas.read_csv(\"/home/skipper/school/seaboldgit/talks/pydata/data/electoral_votes.csv\")\n",
    "electoral_votes.sort(\"State\", inplace=True).reset_index(drop=True, inplace=True);\n",
    "red_states = [\"Alabama\", \"Alaska\", \"Arkansas\", \"Idaho\", \"Kentucky\", \"Louisiana\",\n",
    "              \"Oklahoma\", \"Wyoming\"]\n",
    "blue_states = [\"Delaware\"]#, \"District of Columbia\"]\n",
    "results.name = \"Poll\"\n",
    "results = results.reset_index()\n",
    "results = results.merge(electoral_votes, on=\"State\", how=\"left\").set_index(\"State\")\n",
    "results[\"obama\"] = 0\n",
    "results[\"romney\"] = 0\n",
    "results.ix[results[\"Poll\"] > 0, [\"obama\"]] = 1\n",
    "results.ix[results[\"Poll\"] < 0, [\"romney\"]] = 1\n",
    "results.ix[red_states, [\"romney\"]] = 1\n",
    "results.ix[blue_states, [\"obama\"]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print results[\"Votes\"].mul(results[\"obama\"]).sum() + 3\n",
    "print results[\"Votes\"].mul(results[\"romney\"]).sum() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CCPR Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Component-Component plus residual plots. Partial residual plots attempt to show the relationship between a given independent variable and the response variable given that other independent variables are also in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.regressionplots import plot_ccpr_ax\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "fig = plot_ccpr_ax(mod, 11, ax=ax)\n",
    "ax = fig.axes[0]\n",
    "ax.set_title(\"log(median_income)*B_11 + Resid vs log(median_income)\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.regressionplots import plot_ccpr_ax\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "fig = plot_ccpr_ax(mod, 9, ax=ax)\n",
    "ax = fig.axes[0]\n",
    "ax.set_title(\"per_hisp*B_9 + resid vs per_hisp\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = mod.model.data.orig_exog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[X.columns[:6]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[X.columns[6:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_disc = mod.outlier_test(\"fdr_bh\")\n",
    "false_disc.sort(\"unadj_p\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bonf = mod.outlier_test(\"sidak\")\n",
    "bonf.sort(\"unadj_p\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infl = mod.get_influence()\n",
    "table = infl.summary_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for stat in table.columns:\n",
    "    print stat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Measure the influence of points on prediction\n",
    "\n",
    "$$\\text{DFFITS}=\\frac{\\hat{y}-\\hat{y}_{i}}{s_i\\sqrt{h_{ii}} }$$\n",
    "\n",
    "points greater than\n",
    "\n",
    "$$2\\left\\(\\frac{p}{\\text{nobs}} \\right\\)^{1/2}$$\n",
    "\n",
    "might be cause for concern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print 2*np.sqrt(mod.df_model/mod.nobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dffits = np.abs(table['dffits'].copy())\n",
    "dffits.sort()\n",
    "dffits[::-1][:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indicate influential observations, where you might want more data. \n",
    "\n",
    "Overall fit change with deleted observation.\n",
    "\n",
    "$$\\text{Cook's D}=\\frac{e_i^2}{p\\text{MSE}\\frac{h_{ii}}{(1-h_{ii})^2}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print 4/mod.nobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cooks_d = table[\"cooks_d\"].copy()\n",
    "cooks_d.sort()\n",
    "print cooks_d[::-1][:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_resid = np.abs(table.student_resid.copy())\n",
    "student_resid.sort()\n",
    "student_resid[::-1][:15]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
